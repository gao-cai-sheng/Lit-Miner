"""
è‡ªåŠ¨PDFä¸‹è½½æ¨¡å—

åŠŸèƒ½:
1. PMID â†’ DOI è½¬æ¢
2. å®‰å…¨ä¸‹è½½PDF (ä½¿ç”¨Playwrightæ¨¡æ‹Ÿæµè§ˆå™¨)
3. æ‰¹é‡ä¸‹è½½ç®¡ç† (å¸¦é€Ÿç‡é™åˆ¶)
"""

import os
import time
import asyncio
from typing import List, Dict, Any, Tuple
from Bio import Entrez
from playwright.async_api import async_playwright


def pmid_to_doi(pmid: str, email: str = "your_email@example.com") -> str:
    """
    é€šè¿‡PubMed APIå°†PMIDè½¬æ¢ä¸ºDOI
    
    Args:
        pmid: PubMed ID
        email: Entrez APIæ‰€éœ€çš„email
        
    Returns:
        DOIå­—ç¬¦ä¸²,å¦‚æœæœªæ‰¾åˆ°è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    Entrez.email = email
    
    try:
        handle = Entrez.efetch(db="pubmed", id=pmid, retmode="xml")
        record = Entrez.read(handle)
        handle.close()
        
        # ä»ArticleIdListä¸­æŸ¥æ‰¾DOI
        article_ids = (
            record['PubmedArticle'][0]
            .get('PubmedData', {})
            .get('ArticleIdList', [])
        )
        
        for aid in article_ids:
            if hasattr(aid, 'attributes') and aid.attributes.get('IdType') == 'doi':
                return str(aid)
        
        return ""
    except Exception as e:
        print(f"   âš ï¸  PMID {pmid} è½¬æ¢DOIå¤±è´¥: {e}")
        return ""


def convert_pmids_to_dois(
    papers: List[Dict[str, Any]], 
    email: str = "your_email@example.com"
) -> List[Dict[str, Any]]:
    """
    æ‰¹é‡è½¬æ¢PMIDä¸ºDOI
    
    Args:
        papers: æ–‡çŒ®åˆ—è¡¨,æ¯ä¸ªåŒ…å«'id'(PMID)å­—æ®µ
        email: Entrez APIæ‰€éœ€çš„email
        
    Returns:
        æ›´æ–°åçš„æ–‡çŒ®åˆ—è¡¨,æ·»åŠ äº†'doi'å­—æ®µ
    """
    print("\nğŸ”„ [Step 9] PMID â†’ DOI è½¬æ¢ä¸­...")
    print("-" * 80)
    
    for p in papers:
        pmid = p['id']
        doi = pmid_to_doi(pmid, email)
        p['doi'] = doi
        
        if doi:
            print(f"   âœ… PMID {pmid} â†’ DOI: {doi}")
        else:
            print(f"   âŒ PMID {pmid} æœªæ‰¾åˆ°DOI")
        
        time.sleep(0.5)  # ç¤¼è²Œå»¶è¿Ÿ,é¿å…APIé™æµ
    
    print("-" * 80)
    return papers


async def download_pdf_safe(
    doi: str, 
    pmid: str, 
    output_dir: str = "downloaded_pdfs",
    source_url: str = "https://sci-net.xyz"
) -> str:
    """
    å®‰å…¨ä¸‹è½½å•ç¯‡PDF
    
    Args:
        doi: DOI
        pmid: PMID (ç”¨äºå‘½å)
        output_dir: è¾“å‡ºç›®å½•
        source_url: PDFæºç½‘ç«™
        
    Returns:
        ä¸‹è½½çš„PDFæ–‡ä»¶è·¯å¾„,å¤±è´¥è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    os.makedirs(output_dir, exist_ok=True)
    
    url = f"{source_url}/{doi}"
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )
        page = await context.new_page()
        
        pdf_data = None
        
        async def handle_response(response):
            nonlocal pdf_data
            content_type = response.headers.get("content-type", "").lower()
            if "application/pdf" in content_type:
                try:
                    pdf_data = await response.body()
                    print(f"      âœ… PDFæ•è·æˆåŠŸ! å¤§å°: {len(pdf_data)//1024} KB")
                except Exception as e:
                    print(f"      âŒ PDFè¯»å–å¤±è´¥: {e}")
        
        page.on("response", handle_response)
        
        try:
            print(f"      ğŸŒ æ­£åœ¨è®¿é—®: {url}")
            await page.goto(url, wait_until="networkidle", timeout=30000)
            await asyncio.sleep(2)  # ç­‰å¾…PDFåŠ è½½
            
            # æ£€æŸ¥DOMä¸­çš„PDFé“¾æ¥
            if not pdf_data:
                embed_src = await page.evaluate("""() => {
                    const embed = document.querySelector('embed[type="application/pdf"]');
                    if (embed) return embed.src;
                    const iframe = document.querySelector('iframe');
                    if (iframe) return iframe.src;
                    return null;
                }""")
                
                if embed_src:
                    if embed_src.startswith("//"):
                        embed_src = "https:" + embed_src
                    elif embed_src.startswith("/"):
                        from urllib.parse import urljoin
                        embed_src = urljoin(url, embed_src)
                    
                    response = await page.request.get(embed_src)
                    if response.status == 200:
                        pdf_data = await response.body()
                        print(f"      âœ… PDFæ•è·æˆåŠŸ! å¤§å°: {len(pdf_data)//1024} KB")
        
        except Exception as e:
            print(f"      âŒ ä¸‹è½½å¤±è´¥: {e}")
        
        finally:
            await browser.close()
        
        if pdf_data:
            # ä¿å­˜PDF
            safe_doi = doi.replace("/", "_").replace(":", "_")
            filename = f"PMID_{pmid}_{safe_doi}.pdf"
            filepath = os.path.join(output_dir, filename)
            
            with open(filepath, "wb") as f:
                f.write(pdf_data)
            
            print(f"      ğŸ’¾ å·²ä¿å­˜: {filename}")
            return filepath
        else:
            print(f"      âš ï¸  ä¸‹è½½å¤±è´¥,è¯·æ‰‹åŠ¨ä¸‹è½½: {url}")
            return ""


async def batch_download_pdfs(
    papers: List[Dict[str, Any]], 
    delay_seconds: int = 60,
    output_dir: str = "downloaded_pdfs"
) -> List[str]:
    """
    æ‰¹é‡ä¸‹è½½PDF (å¸¦å»¶è¿Ÿ,å®‰å…¨ç­–ç•¥)
    
    Args:
        papers: æ–‡çŒ®åˆ—è¡¨,æ¯ä¸ªåŒ…å«'doi'å’Œ'id'(PMID)å­—æ®µ
        delay_seconds: æ¯ç¯‡ä¸‹è½½é—´éš”ç§’æ•°
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        æˆåŠŸä¸‹è½½çš„PDFæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    print(f"\nğŸ“¥ [Step 10] å¼€å§‹ä¸‹è½½PDF (æ¯ç¯‡é—´éš”{delay_seconds}ç§’)...")
    print("-" * 80)
    
    downloaded_files = []
    
    for i, p in enumerate(papers):
        doi = p.get('doi', '')
        pmid = p['id']
        title = p.get('title', 'Unknown')[:60]
        
        if not doi:
            print(f"\n   [{i+1}/{len(papers)}] PMID {pmid} æ— DOI,è·³è¿‡")
            print(f"      æ ‡é¢˜: {title}...")
            continue
        
        print(f"\n   [{i+1}/{len(papers)}] ä¸‹è½½ PMID {pmid}")
        print(f"      æ ‡é¢˜: {title}...")
        print(f"      DOI: {doi}")
        
        filepath = await download_pdf_safe(doi, pmid, output_dir)
        if filepath:
            downloaded_files.append(filepath)
        
        # å®‰å…¨å»¶è¿Ÿ (é™¤äº†æœ€åä¸€ç¯‡)
        if i < len(papers) - 1:
            print(f"      â³ ç­‰å¾…{delay_seconds}ç§’åç»§ç»­...")
            await asyncio.sleep(delay_seconds)
    
    print("-" * 80)
    print(f"\nâœ… ä¸‹è½½å®Œæˆ! æˆåŠŸ: {len(downloaded_files)}/{len(papers)}")
    return downloaded_files


def download_top_papers(
    papers: List[Dict[str, Any]], 
    top_n: int = 5,
    email: str = "your_email@example.com",
    delay_seconds: int = 60,
    output_dir: str = "downloaded_pdfs"
) -> List[str]:
    """
    ä¸‹è½½è¯„åˆ†æœ€é«˜çš„Nç¯‡æ–‡çŒ®PDF (åŒæ­¥åŒ…è£…å‡½æ•°)
    
    Args:
        papers: æ–‡çŒ®åˆ—è¡¨
        top_n: ä¸‹è½½å‰Nç¯‡
        email: Entrez APIæ‰€éœ€çš„email
        delay_seconds: æ¯ç¯‡ä¸‹è½½é—´éš”ç§’æ•°
        output_dir: è¾“å‡ºç›®å½•
        
    Returns:
        æˆåŠŸä¸‹è½½çš„PDFæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    # æå–è¯„åˆ†æœ€é«˜çš„Nç¯‡
    top_papers = sorted(papers, key=lambda x: x.get('score', 0), reverse=True)[:top_n]
    
    print(f"\nğŸ“¥ [Step 8] å‡†å¤‡ä¸‹è½½è¯„åˆ†æœ€é«˜çš„ {top_n} ç¯‡æ–‡çŒ®PDF...")
    print("-" * 80)
    for i, p in enumerate(top_papers):
        print(f"   {i+1}. [åˆ†æ•°:{p.get('score', 0)}] {p.get('title', 'Unknown')[:60]}...")
        print(f"      PMID: {p['id']}")
    print("-" * 80)
    
    # Step 9: PMID â†’ DOI
    top_papers_with_doi = convert_pmids_to_dois(top_papers, email)
    
    # Step 10: æ‰¹é‡ä¸‹è½½
    downloaded_files = asyncio.run(
        batch_download_pdfs(top_papers_with_doi, delay_seconds, output_dir)
    )
    
    return downloaded_files


if __name__ == "__main__":
    # æµ‹è¯•ç”¨ä¾‹
    test_papers = [
        {
            'id': '36054302',
            'title': 'Clinical outcomes of dental implants in patients with and without history of periodontitis',
            'score': 15
        }
    ]
    
    print("ğŸ§ª æµ‹è¯•PDFä¸‹è½½æ¨¡å—...")
    downloaded = download_top_papers(
        test_papers, 
        top_n=1, 
        email="test@example.com",
        delay_seconds=5  # æµ‹è¯•æ—¶ä½¿ç”¨è¾ƒçŸ­å»¶è¿Ÿ
    )
    
    print(f"\nâœ… æµ‹è¯•å®Œæˆ! ä¸‹è½½æ–‡ä»¶: {downloaded}")
